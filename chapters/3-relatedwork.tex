\chapter{Related Work}

\section{Dostoevsky}
\label{Dostoevsky}
An optimization of LSM-trees was introduced in 2018 by Niv Dayan and Stratos Idreos. Their research introduces a concept called \emph{Dostoevsky}, in full \emph{Space-Time Optimized Evolvable Scalable Key-Value store}\cite{Dostoevsky}. The solution consists of taking advantage of the different merge policies \emph{tiering} and \emph{leveling} to find the best trade-off between update costs and lookup costs. An important find in their research is that by only conducting merge operations on the largest level, the update cost is improved without affecting lookup or storage costs to an important extent. As updates in LSM-trees are executed by sending it down through the levels, old entries in the largest level are outdated and takes up unnecessary space. In addition, all entries will be merged in every level since outdated entries are not removed until its updated value reaches the largest level.\newline 

To take advantage of these characteristics, a design solution called \emph{Lazy Leveling} is introduced. Lazy Leveling is designed so that only the largest level conducts any merge operations, while all levels above consists of a tiering merge policy. By having this implementation the cost of merging entries at each level is avoided, which in turn reduces the update cost. To be able to tune the design of the LSM-tree, Lazy Leveling is incorporated in another design solution called \emph{Fluid LSM-tree}. In this approach, the largest level is also separated from the smaller ones. This is done by assigning a maximum run size of $Z$ to the largest level, while a maximum run size of $K$ is given to the levels above. To accommodate these sizes, each level also have an \emph{active run} with a size threshold of $T/K$ or $T/Z$ for the smaller and largest levels respectively. $T$ is set to be the ratio between adjacent levels. When these active runs reaches their threshold, their runs are merged into the lower level's active run. The use of Lazy Leveling in the Fluid LSM-tree comes into effect when setting the parameters $K=T-1$ and $Z = 1$. If both parameters are set to $T-1$, the LSM-tree has a tiering merge policy. With parameters set to $1$, the merge policy chosen is leveling. \newline

In order to tune the Fluid LSM-tree correctly according to the application area, the tuning parameters are set while having a constraint on space amplification. The goal is to optimize throughput by looking at update cost, zero-result point lookup cost, non-zero result point lookup cost and range lookup cost. Each of these values are weighted and multiplied by the time it takes to read a block from storage. In order to check the worst-case scenario, the different values are found by setting different parameters for $T$, $Z$ and $K$. The calculation is then iterated. The automatic way of finding the best settings for the parameters, as explained above, is called Dostoevsky. This solution is shown to have much better results than existing solutions such as RocksDB\cite{Dostoevsky}. This is due to the fact that RocksDB only uses leveling, while Dostoevsky is able to change the merge policy of its levels in-between workloads.

\section{Merging R-trees}
Another approach to assemble R-trees was proposed in 2004 by Vasaitis, Nanopoulos and Bozanis\cite{MergingRtree}. Instead of using the bulk-insertion methods already in use, their method lookes at merging two trees by taking advantage of the R-trees existing structure. It also does not make any assumptions about the data distribution which is the case in for example STLT, where the data is assumped to be skewed\cite{STLT}. The structure of the merging process consists of a splitting step similar to the one in R*-trees, tree insertion based on specific critera and a merging algorithm. In order to merge two trees, the tree with the smallest height or the fewest elements are merged into the larger tree. The inserted tree is referred to as \emph{the giving tree}, while the tree inserted into is referred to as \emph{the receiving tree}. \newline

To be able to perform the merge, two buffers of variable size are attached to every accessed node in the receiving tree. These are called \emph{insertion queue} and \emph{local insertion queue}. The insertion queue is used to store entries that are meant to be stored in the node itself and its child nodes. While the local insertion queue only stores entries that are meant to be stored in the node itself. In order to access these queues, additional external memory is needed compared to the traditional insertion method for R-trees. Only one page is needed to store the current node in the traditional insertion method, while $M+3$ pages are needed for the merging method. 2 pages for the insertion queue and 1 page for the local insertion queue in the node, and $M$ pages for the insertion queue in the child nodes.\newline

The splitting method applied is similar to the one in R*-trees. The only difference is that when a split is conducted, the nodes where the entries are loaded into may also be full. To handle this, the split method is done in an iterative way to the children created from each split, until it is certain that all nodes contain at most $M$ entries. For the tree insertion, different criterias are used to decide if the giving tree's entries can be inserted as whole subtrees or if they need to be divided. This is done by looking at a) the area enlargement created by both the subtree and the sum of the individual entries, and inserting the option that gives the least area enlargement, or b) the overlap enlargement created in the current node by inserting the subtree and the individual entries, and inserting the option that gives the least overlap enlargement. The area criterion is used when the subtree is meant to be in a lower level of the receiving tree than the current one, while the overlap criterion is used when the subtree is meant to be in the current level.\newline

The merging algorithm is executed by first picking the giving and receiving tree based on their sizes. Then the giving tree's root is inserted into the insertion queue of the receiving tree's root. Further, the tree insertion is executed and when a split occurs because of overflow, a new root is created for the receiving tree before the old root and the newly created nodes are inserted into its insertion queue. This is then done recursively until the merging process is finished. The merging of R-trees is shown to have a good query performance, and being able to execute the merging process efficiently\cite{MergingRtree}.