\chapter{Implementation}

In this thesis I aim to create an LSM-structured implementation of R-trees, which in turn will be write-optimized. To be able to handle a high workload of write operations without compromising query performance, a bulk-insertion technique such as GBI\cite{GBI} or Seeded Clustering\cite{SeededClustering} will be used to make sure that the index structure is not degraded too much. In addition, the use of such techniques will hopefully also generate better storage utilisation which is needed to avoid unnecessary search operations. I have chosen to call my implementation a \emph{Rectangle-Structured Merge Tree} or RSM-Tree.

\section{Overview}
In order to implement an R-tree index while having a LSM-tree structure, there are some important design choices that need to be evaluated. The first is the ordering of the data, as R-trees are used for multi-dimensional data, while LSM-trees are not. In order to do this, the use of space-filling curves are needed, such as Z-order curve or Hilbert curve. In my implementation, the main ordering technique will be Z-order curve, but both curves might be tested. Another important aspect is how to merge the data from the upper levels to the lower levels. To do this I have chosen to use bulk-insertion methods which looks at loading smaller R-trees into larger ones. By doing this, the costly operation of creating R-trees from scratch will not be needed with every merge.\newline

Lastly, the choice of merge policies is important. As inspired from Dostoevsky\cite{Dostoevsky}, I will try different combinations of tiering and leveling policies as explained in Section \ref{Dostoevsky}. This is done in order to tune the write and search performance as needed.  

\section{Structure}
The general structure of the RSM-tree is presented in Figure \ref{fig:RSMTree}. The in-memory component $C_0$ stores each data object in their own MBR, given as $A, B, ..., F$. These are sequentially ordered following the chosen space-filling curve. This is done because it is crucial that the items are sequentially ordered when performing search operations in LSM-trees. In addition to this, a sequential structure is beneficial when merging the data to the lower levels, as will be further explained in Section \ref{sect:RSM-Merging}. In the second level $C_1$, the MBRs will be merged together to create R-trees from scratch, given as $R_2, R_3, R_4, R_5$. The lowest level $C_2$, is structured as the main R-tree, where trees from $C_2$ will be bulk-inserted into the correct positions in the main R-tree.  
\begin{figure}[ht]
     \centering
     \begin{subfigure}{0.45\textwidth}
         \centering
         \includegraphics[width=\textwidth]{figures/RSMTree.pdf}
         \caption{RSM-Tree index structure}
     \end{subfigure}
     \hfill
     \begin{subfigure}{0.45\textwidth}
         \centering
         \includegraphics[width=\textwidth]{figures/RSMTree_space.pdf}
         \caption{RSM-Tree space structure}
     \end{subfigure}
        \caption{RSM-Tree}
        \label{fig:RSMTree}
\end{figure}

The nodes in the RSM-tree are structured as shown in Figure \ref{fig:nodeRSM}. The first value is the Z-order value calculated from the objects minimum bounding rectangle (MBR), while the MBR is the rectangle containing the object. The last element \emph{pointer}, points to either an intermediate node's children nodes or an object identifier. The calculation of the z-order values is explained in Section \ref{sect:zordering}. 

\begin{figure}[ht]
    \centering
    \includegraphics[scale=0.5]{figures/node_RSM.pdf}
    \caption{RSM-Tree Node structure}
    \label{fig:nodeRSM}
\end{figure}

\section{Space-Filling Curve}
\label{sect:ordering}
The use of a space-filling curve in order to create the RSM-tree is crucial in order to sequentially order the objects in level $C_0$. As Z-ordering is simpler to implement, as well as being less costly, it will be the implemented technique. This is also because it has proven to perform well with a low number of dimensions\cite{IrregularSpace}, which will be the case when inserting test data. When further developing the RSM-tree, it is also possible to implement the Hilbert curve ordering technique, but this will not be a priority during the first implementation. 

\subsection{Z-ordering}
\label{sect:zordering}
To calculate the Z-values of each object, the $x$ and $y$ coordinates of the object's MBR is found. These coordinates can be chosen as the outer corner of a rectangle or as the rectangle's center. In my implementation, the coordinates will be calculated from the center. These coordinates will then be represented as their binary value. In order to calculate the binary representation of the two coordinates together, their individual values are interleaved. Interleaving is done by extending $x$ and $y$ of length $n$ to length $2n$, where each value from $x$ is put in odd positions and each value from $y$ is put in even positions\cite{interleave}. This can also be done in an opposite manner. An example of this process is shown in Figure \ref{fig:bitInterleaving}, inspired by \cite{zorder_figure}. The space is considered for integers between 0 and 7, but only showing the first quadrant in Figure \ref{fig:zspace}. The interleaving process of this first quadrant is demonstrated in Figure \ref{fig:zinterleave}, where the $x$ coordinate is set at even positions while the $y$ coordinate is set at odd positions. By finding the binary representation of a position, we can use this information to compare objects when ordering them. 

\begin{figure}[ht]
     \centering
     \begin{subfigure}{0.45\textwidth}
         \centering
         \includegraphics[width=\textwidth]{figures/zorder_process_graph.pdf}
         \caption{Z-order mapping in space}
         \label{fig:zspace}
     \end{subfigure}
     \hfill
      \begin{subfigure}{0.45\textwidth}
     \centering
     \includegraphics[width=\textwidth]{figures/zorder_process_interleaving.pdf}
     \caption{Interleaving process}
     \label{fig:zinterleave}
     \end{subfigure}
    \hfill
    \caption{Z-order calculation process}
    \label{fig:bitInterleaving}
\end{figure}

\section{Merging}
\label{sect:RSM-Merging}
The merging technqiue for the RSM-tree is based on both construction of R-trees from scratch, in addition to using bulk-insertion into existing trees. In my first implementation there will be three levels that each have some important characteristics. 

\subsection{Level $C_0$: In-memory component}
The in-memory component consists of single objects, ordered by the z-value of the center of each object's MBR. As in the regular LSM-tree, objects are sent to the lower level, $C_1$, when the total number of objects reach a certain threshold. 

\subsection{Level $C_1$: Upper-level storage component}
In an ideal solution, all elements coming from $C_0$ would be indexed in the same R-tree. But, as the trees in $C_1$ are constructed to be bulk-loaded into the main R-tree in level $C_2$, there are some considerations that need to be discussed. One important factor is the distribution of the data. If we were to construct R-trees based on their location in space (e.g., divide the space into the four squares given in Figure \ref{fig:RSMTree}), we could end up with having to restructure the main R-tree in $C_2$ if the data is skewed. This is due to the fact that we cannot insert R-trees into the same position in the main R-tree without requiring restructuring. This entails node splitting when overflow occurs, which in turn will lead to uneven depths in the different nodes, which leads to restructuring of the whole tree. This is due to the constraint that all leaf nodes must be at the same level of the tree. Another aspect is the area in space covered by each R-tree in $C_1$. If we simply create an R-tree from all objects coming from $C_0$, we could end up with intermediate nodes that cover a lot of empty space. This is because the objects might not be close to each other. When these R-trees are bulk-inserted into the main R-tree, there is a higher chance for overlapping MBR's in intermediate nodes, as they each might cover a large area. \newline

One way of handling these issues can be to use seeded clustering\cite{SeededClustering} and to look for outliers. By maintaining a clustering scheme, based on the top $k$ levels of the main R-tree, we can adjust the clustering to the data distribution. To implement this, the RSM-tree will have a seeded R-tree stored in $C_1$, which will be updated at an evenly rate. The data that comes from $C_0$ will then be assigned to clusters, and an R-tree per cluster will be created. By doing this, the main R-tree will most likely avoid too many overlapping MBR's in intermediate nodes, in addition to reducing the amount of node splits. If there are any outliers, these will be inserted into the main R-tree one-by-one. The construction of the R-trees in $C_1$ will follow the structure of the general R-tree proposed by Guttman\cite{r-tree}. If time allows, the Sort-Tile-Recursive packing method\cite{STR} might also be implemented as all objects for the R-trees are known before the construction.

\subsection{Level $C_2$: Lower-level storage component}
In the lowest level, $C_2$, the main R-tree will be stored. The R-tree is dynamically updated by bulk-insertions from $C_1$. As the trees coming from the level above are clustered according to the top $k$ levels of the main tree, we reduce the need for node splits. If node underflow should occur however, it is handled in the same way as described by bulk-insertion by seeded clustering\cite{SeededClustering}. If the incoming tree suffers from underflow, the elements in the incoming tree is reinserted at the target node in the main tree. Another important aspect is the repacking method, which is done if the insertion creates many overlapping entries. If a node overflows, the quadratic split method\cite{r-tree} is used. An important part of using seeded clustering is to find out how often a seeded tree should be generated and sent to level $C_1$. This is something that needs to be tested during the implementation, as generating it too often will use unnecessary resources, while if not updated often enough will lead to bad distribution for the incoming R-trees. 

\subsection{Merge policies}
\textbf{Skriv noe om de forskjellige variantene du kan prøve ut, hva som er hovedkonseptet...}

\section{Insertion, Updates, Deletions}
Insertion, updates and deletions will be conducted in a similar manner as in the traditional LSM-tree. When an entry is inserted, an MBR is created for the object as well as calculating its z-order value. This element is then inserted in $C_0$, in the correct position according to its z-order value. The rest of the insertion process will be as described in Section \ref{sect:RSM-Merging}. Deletions are done by either deleting the object directly, if it is present in $C_0$. If this is not the case, a deletion block is created and sent through the levels. A deletion block will consist of the same elements as a regular node, but will have an additional entry indicating that it is meant to be deleted. This is then used in $C_1$ and $C_2$ to search for overlapping MBR's to identify the object to delete. Updates are handled by first deleting an entry, followed by inserting a new one. 
